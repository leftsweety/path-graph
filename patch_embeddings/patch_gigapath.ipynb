{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prov-GigaPath inference demo\n",
    "\n",
    "The Prov-GigaPath models can be accessed from [HuggingFace Hub](https://huggingface.co/prov-gigapath/prov-gigapath).\n",
    "\n",
    "You need to agree to the terms to access the models. Once you have the necessary access, set your HuggingFace read-only token as an environment variable:\n",
    "\n",
    "Please use your own 'HF_TOKEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizx43/anaconda3/envs/gigapath/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "os.environ['CURL_CA_BUNDLE']=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tile and slide encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizx43/anaconda3/envs/gigapath/lib/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/lizx43/anaconda3/envs/gigapath/lib/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/lizx43/anaconda3/envs/gigapath/lib/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile encoder param # 1134953984\n",
      "dilated_ratio:  [1, 2, 4, 8, 16]\n",
      "segment_length:  [1024, 5792, 32768, 185363, 1048576]\n",
      "Number of trainable LongNet parameters:  85148160\n",
      "Global Pooling: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizx43/anaconda3/envs/gigapath/lib/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/lizx43/anaconda3/envs/gigapath/lib/python3.9/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'cdn-lfs-us-1.huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d9e4de38504fc498a7083c255e683b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "slide_encoder.pth:   0%|          | 0.00/345M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Successfully Loaded Pretrained GigaPath model from hf_hub:prov-gigapath/prov-gigapath \u001b[00m\n",
      "Slide encoder param # 86330880\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../prov-gigapath')\n",
    "from gigapath.pipeline import load_tile_slide_encoder\n",
    "# load the tile and slide encoder models\n",
    "tile_encoder, slide_encoder_model = load_tile_slide_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\n",
      "     - Powered by -     \n",
      "   _______   __________   \n",
      "  / __/ _ | / __/_  __/   https://fast.eriksmistad.no\n",
      " / _// __ |_\\ \\  / /               v4.9.2\n",
      "/_/ /_/ |_/___/ /_/       \n",
      "\n",
      "\u001b[0m\u001b[1mWARNING [137369891505984] Unable to open X display. Disabling visualization.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import fast\n",
    "import openslide\n",
    "\n",
    "def patch_svs(image_path, output_folder, tile_size=256, magnification=5):\n",
    "    slide = openslide.OpenSlide(image_path)\n",
    "    level = slide.get_best_level_for_downsample(magnification)\n",
    "    print('level --- ', magnification, level)\n",
    "    importer = fast.WholeSlideImageImporter\\\n",
    "        .create(image_path)\n",
    "\n",
    "    # Do tissue segmentation to select patches from tissue only\n",
    "    tissueSegmentation = fast.TissueSegmentation.create()\\\n",
    "        .connect(importer)\n",
    "    patchGenerator = fast.PatchGenerator.create(tile_size, tile_size, level=0, magnification=magnification)\\\n",
    "        .connect(0, importer)\\\n",
    "        .connect(1, tissueSegmentation)\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    for i, patch in enumerate(fast.DataStream(patchGenerator)):\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "        x=int(patch.getTransform().getTranslation()[0][0])\n",
    "        y=int(patch.getTransform().getTranslation()[1][0])\n",
    "        tile_path = os.path.join(output_folder, f'{x}x_{y}y.jpg')\n",
    "        fast.ImageExporter.create(tile_path)\\\n",
    "            .connect(patch)\\\n",
    "            .run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gigapath.pipeline import run_inference_with_tile_encoder\n",
    "from gigapath.pipeline import run_inference_with_slide_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_id_df = pd.read_csv('../get_data/data_sheets/image_id_res.csv')\n",
    "concentriq_image_dir = '/concentriq/'\n",
    "sys.path.append('..')\n",
    "#Check the Slide Path and storageKey\n",
    "from utils.slide_utils import show_slide_info\n",
    "# concentriq_image_path = slides_id_df['storageKey'][0]\n",
    "concentriq_image_path='default/users/73/images/165325/083-0023-0060-B1-01.svs'\n",
    "# show_slide_info(concentriq_image_dir+concentriq_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_fun import ensure_dir, check_file_exist\n",
    "def generate_tile_slide_embedings(image_info_df, output_patch_dir, save_embed_dir, magnification):\n",
    "    ensure_dir(output_patch_dir)\n",
    "    ensure_dir(save_embed_dir)\n",
    "\n",
    "    concentriq_image_dir = '/concentriq/'\n",
    "    for row in image_info_df.iterrows():\n",
    "        row = row[1]\n",
    "        slide_id = row['images_id']\n",
    "        if check_file_exist(save_embed_dir+f'{slide_id}_slide_tensor.pt'):\n",
    "            continue\n",
    "        # These slides can't be tiled by pyfast\n",
    "        if slide_id in [225441, 225415, 327476, 331272, 234962, 330698]:\n",
    "            continue\n",
    "        print(slide_id, 'start')\n",
    "        storage_key = row['storageKey']\n",
    "        image_path = concentriq_image_dir+storage_key\n",
    "        output_folder = output_patch_dir+str(slide_id)\n",
    "\n",
    "        patch_svs(image_path, output_folder, tile_size=256, magnification=magnification)\n",
    "        \n",
    "        input_giga_paths = [os.path.join(output_folder, img) for img in os.listdir(output_folder) if img.endswith('.jpg')]\n",
    "        print(f\"Found {len(input_giga_paths)} image tiles\")\n",
    "        tile_encoder_outputs = run_inference_with_tile_encoder(input_giga_paths, tile_encoder)\n",
    "\n",
    "        for k in tile_encoder_outputs.keys():\n",
    "            print(f\"tile_encoder_outputs[{k}].shape: {tile_encoder_outputs[k].shape}\")\n",
    "\n",
    "        slide_embeds = run_inference_with_slide_encoder(slide_encoder_model=slide_encoder_model, **tile_encoder_outputs)\n",
    "        torch.save(tile_encoder_outputs, save_embed_dir+f'{slide_id}_tile_tensor.pt')\n",
    "        torch.save(slide_embeds, save_embed_dir+f'{slide_id}_slide_tensor.pt')\n",
    "\n",
    "        # delete_directory(output_folder)\n",
    "        print(slide_id, 'over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./5XTiles/ already exists.\n",
      "Directory ./5XEmbeddings/ already exists.\n",
      "157799 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137347165312576] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 69 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([69, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([69, 2])\n",
      "157799 over\n",
      "190903 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343356892736] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 47 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([47, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([47, 2])\n",
      "190903 over\n",
      "133583 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343348500032] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 33 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([33, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([33, 2])\n",
      "133583 over\n",
      "220926 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343340107328] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 278 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([278, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([278, 2])\n",
      "220926 over\n",
      "133586 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343256229440] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 10 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([10, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([10, 2])\n",
      "133586 over\n",
      "157826 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343247836736] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 882 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 7/7 [00:08<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([882, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([882, 2])\n",
      "157826 over\n",
      "196011 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343239444032] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 457 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 4/4 [00:04<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([457, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([457, 2])\n",
      "196011 over\n",
      "157818 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343231051328] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 14 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([14, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([14, 2])\n",
      "157818 over\n",
      "160110 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343222658624] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 11 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([11, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([11, 2])\n",
      "160110 over\n",
      "174098 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343214265920] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 15 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([15, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([15, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174098 over\n",
      "157825 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137343205873216] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 53 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([53, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([53, 2])\n",
      "157825 over\n",
      "160100 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342752912960] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 1155 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([1155, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([1155, 2])\n",
      "160100 over\n",
      "331064 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342744520256] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 16 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([16, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331064 over\n",
      "190989 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342736127552] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 282 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([282, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([282, 2])\n",
      "190989 over\n",
      "330657 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342618695232] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 1755 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([1755, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([1755, 2])\n",
      "330657 over\n",
      "337131 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342610302528] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 1755 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([1755, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([1755, 2])\n",
      "337131 over\n",
      "327927 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342601909824] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 3 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00, 21.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([3, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([3, 2])\n",
      "327927 over\n",
      "327808 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342350259776] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 32 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([32, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([32, 2])\n",
      "327808 over\n",
      "190968 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342341867072] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 46 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([46, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([46, 2])\n",
      "190968 over\n",
      "327544 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137342333474368] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 82 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([82, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([82, 2])\n",
      "327544 over\n",
      "190913 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341712725568] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 36 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([36, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([36, 2])\n",
      "190913 over\n",
      "225500 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341704332864] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 96 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([96, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([96, 2])\n",
      "225500 over\n",
      "328020 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341695940160] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 3 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([3, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([3, 2])\n",
      "328020 over\n",
      "327805 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341687547456] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 21 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([21, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([21, 2])\n",
      "327805 over\n",
      "327851 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341679154752] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 8 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([8, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([8, 2])\n",
      "327851 over\n",
      "327835 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341670762048] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 73 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([73, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([73, 2])\n",
      "327835 over\n",
      "328050 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341662369344] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 24 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([24, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([24, 2])\n",
      "328050 over\n",
      "327669 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341175854656] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 21 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([21, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([21, 2])\n",
      "327669 over\n",
      "327966 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341167461952] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 26 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([26, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([26, 2])\n",
      "327966 over\n",
      "327465 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341159069248] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 16 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([16, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327465 over\n",
      "327939 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341150676544] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 14 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([14, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([14, 2])\n",
      "327939 over\n",
      "327980 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341142283840] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 27 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([27, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([27, 2])\n",
      "327980 over\n",
      "327908 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341133891136] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 39 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([39, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([39, 2])\n",
      "327908 over\n",
      "327714 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341125498432] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 129 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([129, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([129, 2])\n",
      "327714 over\n",
      "327779 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137341008082496] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 64 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([64, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([64, 2])\n",
      "327779 over\n",
      "328026 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340999689792] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 62 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([62, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([62, 2])\n",
      "328026 over\n",
      "190998 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340991297088] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 79 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([79, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([79, 2])\n",
      "190998 over\n",
      "327857 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340236330560] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 12 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([12, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([12, 2])\n",
      "327857 over\n",
      "327556 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340227937856] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 9 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([9, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([9, 2])\n",
      "327556 over\n",
      "327538 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340219545152] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 19 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([19, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([19, 2])\n",
      "327538 over\n",
      "337207 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340211152448] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 28 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([28, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([28, 2])\n",
      "337207 over\n",
      "337178 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340202759744] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 51 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([51, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([51, 2])\n",
      "337178 over\n",
      "354788 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340194367040] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 56 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([56, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([56, 2])\n",
      "354788 over\n",
      "327661 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340185974336] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 8 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([8, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([8, 2])\n",
      "327661 over\n",
      "327696 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340068558400] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 15 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([15, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([15, 2])\n",
      "327696 over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327963 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340060165696] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 60 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([60, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([60, 2])\n",
      "327963 over\n",
      "328023 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137340051772992] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n",
      "0\n",
      "Found 18 image tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference with tile encoder: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_encoder_outputs[tile_embeds].shape: torch.Size([18, 1536])\n",
      "tile_encoder_outputs[coords].shape: torch.Size([18, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328023 over\n",
      "327773 start\n",
      "level ---  5 1\n",
      "\u001b[1mWARNING [137339397469760] Requested magnification level does not exist in image pyramid. Will now try to sample from a lower level and resize. This may increase runtime.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in [20, 10, 5]:\n",
    "# for i in [5]:\n",
    "    output_patch_dir = f'./{i}XTiles/'\n",
    "    save_embed_dir = f'./{i}XEmbeddings/'\n",
    "    generate_tile_slide_embedings(slides_id_df, output_patch_dir, save_embed_dir, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't patch these slides\n",
    "#10x 331272\n",
    "#5X 225441 #225415 #327476 #331272 #234962 #330698\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gigapath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
